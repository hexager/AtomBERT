{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-29T20:37:00.849802Z","iopub.execute_input":"2025-03-29T20:37:00.850152Z","iopub.status.idle":"2025-03-29T20:37:00.854715Z","shell.execute_reply.started":"2025-03-29T20:37:00.850124Z","shell.execute_reply":"2025-03-29T20:37:00.853730Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from transformers import BertTokenizerFast\nfrom torch.utils.data import Dataset, DataLoader\nfrom datasets import load_dataset\nfrom datasets import Dataset as HFDataset\nimport torch\nimport torch.nn.functional as F\nimport math\nimport torch.nn as nn\nimport torch.optim as optim\nfrom tqdm.notebook import tqdm\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"wandbpass\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T20:37:00.855876Z","iopub.execute_input":"2025-03-29T20:37:00.856250Z","iopub.status.idle":"2025-03-29T20:37:01.190551Z","shell.execute_reply.started":"2025-03-29T20:37:00.856221Z","shell.execute_reply":"2025-03-29T20:37:01.189885Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import wandb\nwandb.login(key=secret_value_0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T20:37:01.191669Z","iopub.execute_input":"2025-03-29T20:37:01.191908Z","iopub.status.idle":"2025-03-29T20:37:10.218991Z","shell.execute_reply.started":"2025-03-29T20:37:01.191888Z","shell.execute_reply":"2025-03-29T20:37:10.218258Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhexager\u001b[0m (\u001b[33mhexager-manipal\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\nsentence = \"By the way, we ball\"\ntokens = tokenizer.tokenize(sentence)\nprint(tokens)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T20:37:10.220164Z","iopub.execute_input":"2025-03-29T20:37:10.220632Z","iopub.status.idle":"2025-03-29T20:37:16.031934Z","shell.execute_reply.started":"2025-03-29T20:37:10.220606Z","shell.execute_reply":"2025-03-29T20:37:16.030989Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aace3ccaeb8e4fde8b63e6126bd6fbfa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec320f13e33d4a2894d898bc900a7e34"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"153215f056d04a0caf33b7508091cc5b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5807db28bd6a446e9baf7ea6ad91191f"}},"metadata":{}},{"name":"stdout","text":"['by', 'the', 'way', ',', 'we', 'ball']\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"mnli_dataset = load_dataset(\"multi_nli\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T20:37:16.032714Z","iopub.execute_input":"2025-03-29T20:37:16.033201Z","iopub.status.idle":"2025-03-29T20:37:26.901124Z","shell.execute_reply.started":"2025-03-29T20:37:16.033176Z","shell.execute_reply":"2025-03-29T20:37:26.900485Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/8.89k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34cb5aef9bd24dd08bd5136eef043a66"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/214M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60cb40726fd748ce85c7f6bb34a6042c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)alidation_matched-00000-of-00001.parquet:   0%|          | 0.00/4.94M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59613cc3fb444b44bd00e9581aa85309"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)dation_mismatched-00000-of-00001.parquet:   0%|          | 0.00/5.10M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c3a2d08adc4943c38532f679bdaa986c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/392702 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e33fcaf846d348928fa8cea1331279ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation_matched split:   0%|          | 0/9815 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2dfb05705f83444eaf3a1630d515b797"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation_mismatched split:   0%|          | 0/9832 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b355735466f749f0a0a448b3e6022666"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"val_data = mnli_dataset[\"validation_matched\"] # You can also try \"validation_mismatched\"\ntrain_data = mnli_dataset[\"train\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T20:37:26.901972Z","iopub.execute_input":"2025-03-29T20:37:26.902297Z","iopub.status.idle":"2025-03-29T20:37:26.905766Z","shell.execute_reply.started":"2025-03-29T20:37:26.902265Z","shell.execute_reply":"2025-03-29T20:37:26.904936Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"print(mnli_dataset['train'][0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T20:37:26.908284Z","iopub.execute_input":"2025-03-29T20:37:26.908478Z","iopub.status.idle":"2025-03-29T20:37:26.958852Z","shell.execute_reply.started":"2025-03-29T20:37:26.908460Z","shell.execute_reply":"2025-03-29T20:37:26.958099Z"}},"outputs":[{"name":"stdout","text":"{'promptID': 31193, 'pairID': '31193n', 'premise': 'Conceptually cream skimming has two basic dimensions - product and geography.', 'premise_binary_parse': '( ( Conceptually ( cream skimming ) ) ( ( has ( ( ( two ( basic dimensions ) ) - ) ( ( product and ) geography ) ) ) . ) )', 'premise_parse': '(ROOT (S (NP (JJ Conceptually) (NN cream) (NN skimming)) (VP (VBZ has) (NP (NP (CD two) (JJ basic) (NNS dimensions)) (: -) (NP (NN product) (CC and) (NN geography)))) (. .)))', 'hypothesis': 'Product and geography are what make cream skimming work. ', 'hypothesis_binary_parse': '( ( ( Product and ) geography ) ( ( are ( what ( make ( cream ( skimming work ) ) ) ) ) . ) )', 'hypothesis_parse': '(ROOT (S (NP (NN Product) (CC and) (NN geography)) (VP (VBP are) (SBAR (WHNP (WP what)) (S (VP (VBP make) (NP (NP (NN cream)) (VP (VBG skimming) (NP (NN work)))))))) (. .)))', 'genre': 'government', 'label': 1}\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"max_seq_length = 128","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T20:39:11.010222Z","iopub.execute_input":"2025-03-29T20:39:11.010495Z","iopub.status.idle":"2025-03-29T20:39:11.013949Z","shell.execute_reply.started":"2025-03-29T20:39:11.010475Z","shell.execute_reply":"2025-03-29T20:39:11.013303Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def tokenize_mnli(examples):\n    return tokenizer(examples['premise'], examples['hypothesis'], max_length=max_seq_length, padding='max_length', truncation=True)\n\ntokenized_train_data = mnli_dataset[\"train\"].map(tokenize_mnli, batched=True, remove_columns=['premise', 'hypothesis'])\ntokenized_val_data = mnli_dataset[\"validation_matched\"].map(tokenize_mnli, batched=True, remove_columns=['premise', 'hypothesis'])\n\nclass MNLIDatasetOptimized(Dataset):\n    def __init__(self, data):\n        self.data = data\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        item = self.data[idx]\n        return {\n            'input_ids': torch.tensor(item['input_ids']),\n            'attention_mask': torch.tensor(item['attention_mask']),\n            'labels': torch.tensor(item['label'])\n        }\n\ntrain_dataset = MNLIDatasetOptimized(tokenized_train_data)\nval_dataset = MNLIDatasetOptimized(tokenized_val_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T20:39:13.782272Z","iopub.execute_input":"2025-03-29T20:39:13.782554Z","iopub.status.idle":"2025-03-29T20:40:11.120847Z","shell.execute_reply.started":"2025-03-29T20:39:13.782533Z","shell.execute_reply":"2025-03-29T20:40:11.119960Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/392702 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b7e93471e424b9dbe880a2c40206267"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/9815 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c790ca2219b4d728568bd12f971d777"}},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"batch_size_finetune = 32 # You can adjust this\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size_finetune, shuffle=True)\nval_dataloader = DataLoader(val_dataset, batch_size=batch_size_finetune)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T20:40:27.097590Z","iopub.execute_input":"2025-03-29T20:40:27.097904Z","iopub.status.idle":"2025-03-29T20:40:27.102266Z","shell.execute_reply.started":"2025-03-29T20:40:27.097878Z","shell.execute_reply":"2025-03-29T20:40:27.101365Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"sample = train_dataset[0]\nprint(sample['input_ids'].shape)\nprint(sample['attention_mask'].shape)\nprint(sample['labels'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T20:40:31.901449Z","iopub.execute_input":"2025-03-29T20:40:31.901723Z","iopub.status.idle":"2025-03-29T20:40:31.937499Z","shell.execute_reply.started":"2025-03-29T20:40:31.901703Z","shell.execute_reply":"2025-03-29T20:40:31.936828Z"}},"outputs":[{"name":"stdout","text":"torch.Size([128])\ntorch.Size([128])\ntensor(1)\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"class MultiHeadSelfAttention(nn.Module):\n    def __init__(self, hidden_size, num_attention_heads, dropout_rate):\n        super().__init__()\n        self.num_heads = num_attention_heads\n        self.head_dim = hidden_size // num_attention_heads\n        assert self.head_dim * self.num_heads == hidden_size\n\n        self.query = nn.Linear(hidden_size, hidden_size)\n        self.key = nn.Linear(hidden_size, hidden_size)\n        self.value = nn.Linear(hidden_size, hidden_size)\n\n        self.dropout = nn.Dropout(dropout_rate)\n        self.output = nn.Linear(hidden_size, hidden_size)\n    def forward(self, query, key, value, mask=None):\n        batch_size = query.size(0)\n        seq_len_q, seq_len_k, seq_len_v = query.size(1), key.size(1), value.size(1)\n        query = self.query(query)\n        key = self.key(key)\n        value = self.value(value)\n        query = query.view(batch_size, seq_len_q, self.num_heads, self.head_dim).permute(0, 2, 1, 3)\n        key = key.view(batch_size, seq_len_k, self.num_heads, self.head_dim).permute(0, 2, 1, 3)\n        value = value.view(batch_size, seq_len_v, self.num_heads, self.head_dim).permute(0, 2, 1, 3)\n        attention_scores = torch.matmul(query, key.transpose(-2,-1))\n        attention_scores = attention_scores/(self.head_dim**0.5)\n        mask = mask.unsqueeze(1).unsqueeze(2)\n        if mask is not None:\n            attention_scores = attention_scores.masked_fill(mask==0, float('-inf'))\n        attention_weights = F.softmax(attention_scores,dim=-1)\n        scaled_attention = torch.matmul(attention_weights, value)\n        scaled_attention = scaled_attention.permute(0, 2, 1, 3).contiguous().view(batch_size, seq_len_q, self.num_heads * self.head_dim)\n        output = self.output(scaled_attention)\n        return output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T20:43:04.483587Z","iopub.execute_input":"2025-03-29T20:43:04.483885Z","iopub.status.idle":"2025-03-29T20:43:04.491864Z","shell.execute_reply.started":"2025-03-29T20:43:04.483863Z","shell.execute_reply":"2025-03-29T20:43:04.490875Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"class FeedForwardNetwork(nn.Module):\n    def __init__(self, hidden_size, intermediate_size, dropout_rate):\n        super().__init__()\n        self.dense1 = nn.Linear(hidden_size, intermediate_size)\n        self.relu = nn.ReLU()\n        self.dense2 = nn.Linear(intermediate_size, hidden_size)\n        self.dropout = nn.Dropout(dropout_rate)\n\n    def forward(self, x):\n        x = F.relu(self.dense1(x))\n        x = self.dropout(x)\n        x = self.dense2(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T20:43:07.278626Z","iopub.execute_input":"2025-03-29T20:43:07.279055Z","iopub.status.idle":"2025-03-29T20:43:07.285348Z","shell.execute_reply.started":"2025-03-29T20:43:07.278998Z","shell.execute_reply":"2025-03-29T20:43:07.284326Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"class TransformerEncoderLayer(nn.Module):\n    def __init__(self, hidden_size, num_attention_heads, intermediate_size, dropout_rate):\n        super().__init__()\n        self.self_attention = MultiHeadSelfAttention(hidden_size, num_attention_heads, dropout_rate)\n        self.feed_forward = FeedForwardNetwork(hidden_size, intermediate_size, dropout_rate)\n        self.norm1 = nn.LayerNorm(hidden_size)\n        # Removed the second LayerNorm (norm2)\n        self.dropout = nn.Dropout(dropout_rate)\n\n    def forward(self, x, mask):\n        # Self-attention with residual and normalization\n        attention_output = self.self_attention(x, x, x, mask)\n        normed_output1 = self.norm1(attention_output + x)\n        \n        # Feed-forward block with residual, no additional normalization here\n        ff_output = self.feed_forward(normed_output1)\n        final_output = ff_output + normed_output1\n        return final_output\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T20:43:09.792609Z","iopub.execute_input":"2025-03-29T20:43:09.792908Z","iopub.status.idle":"2025-03-29T20:43:09.797739Z","shell.execute_reply.started":"2025-03-29T20:43:09.792887Z","shell.execute_reply":"2025-03-29T20:43:09.796936Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"class FactorizedEmbedding(nn.Module):\n    def __init__(self, vocab_size, embedding_dim, hidden_size, type_vocab_size=2):\n        super().__init__()\n        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n        self.token_type_embeddings = nn.Embedding(type_vocab_size, embedding_dim)\n        self.projection = nn.Linear(embedding_dim, hidden_size)\n\n    def forward(self, input_ids, token_type_ids=None):\n        factor_embeds = self.word_embeddings(input_ids)\n        if token_type_ids is None:\n            token_type_ids = torch.zeros_like(input_ids)\n        token_type_embeds = self.token_type_embeddings(token_type_ids)\n        # Sum the embeddings\n        embeds = factor_embeds + token_type_embeds        \n        project_embeds = self.projection(embeds)\n        return project_embeds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T20:43:14.047965Z","iopub.execute_input":"2025-03-29T20:43:14.048308Z","iopub.status.idle":"2025-03-29T20:43:14.053485Z","shell.execute_reply.started":"2025-03-29T20:43:14.048282Z","shell.execute_reply":"2025-03-29T20:43:14.052577Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"class PositionalEncoding(nn.Module):\n    def __init__(self, hidden_size, max_seq_length, dropout_rate):\n        super().__init__()\n        self.dropout = nn.Dropout(dropout_rate)\n\n        position = torch.arange(0, max_seq_length).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, hidden_size, 2) * -(math.log(10000.0) / hidden_size))\n        pe = torch.zeros(max_seq_length, 1, hidden_size)\n        pe[:, 0, 0::2] = torch.sin(position * div_term)\n        pe[:, 0, 1::2] = torch.cos(position * div_term)\n        self.register_buffer('pe', pe) # Store as a buffer (not a learnable parameter)\n\n    def forward(self, x):\n        seq_length = x.size(1)\n        pe = self.pe[:seq_length].squeeze(1)\n        x = x + pe.unsqueeze(0)\n        x = self.dropout(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T20:43:16.856783Z","iopub.execute_input":"2025-03-29T20:43:16.857184Z","iopub.status.idle":"2025-03-29T20:43:16.865146Z","shell.execute_reply.started":"2025-03-29T20:43:16.857152Z","shell.execute_reply":"2025-03-29T20:43:16.863956Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"class AtomBERT(nn.Module):\n    def __init__(self, vocab_size, embedding_dim, hidden_size, num_layers, \n                 num_attention_heads, intermediate_size, num_classes, max_seq_length, \n                 dropout_rate, type_vocab_size=2):\n        super().__init__()\n        self.embedding = FactorizedEmbedding(vocab_size, embedding_dim, hidden_size, type_vocab_size)\n        self.positional_encoding = PositionalEncoding(hidden_size, max_seq_length, dropout_rate)\n        # Shared encoder layer across all iterations\n        self.encoder_layer = TransformerEncoderLayer(hidden_size, num_attention_heads, intermediate_size, dropout_rate)\n        # Create separate layer norms for each iteration\n        self.layer_norms = nn.ModuleList([nn.LayerNorm(hidden_size) for _ in range(num_layers)])\n        self.dropout = nn.Dropout(dropout_rate)\n        self.num_layers = num_layers\n        self.hidden_size = hidden_size\n\n    def forward(self, input_ids, attention_mask, token_type_ids=None):\n        embeddings = self.embedding(input_ids, token_type_ids)\n        embeddings = self.positional_encoding(embeddings)\n\n        encoder_output = embeddings\n        for ln in self.layer_norms:\n            # Pass through the shared encoder layer\n            output = self.encoder_layer(encoder_output, attention_mask)\n            # Residual connection plus per-iteration layer normalization\n            encoder_output = ln(encoder_output + output)\n        pooled_output = encoder_output[:, 0, :]  # Use [CLS] token\n        pooled_output = self.dropout(pooled_output)\n        return encoder_output, pooled_output\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T20:43:19.134357Z","iopub.execute_input":"2025-03-29T20:43:19.134678Z","iopub.status.idle":"2025-03-29T20:43:19.141143Z","shell.execute_reply.started":"2025-03-29T20:43:19.134652Z","shell.execute_reply":"2025-03-29T20:43:19.140213Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"class AtomBERTForPretraining(nn.Module): # Renamed for clarity\n    def __init__(self, config):\n        super().__init__()\n        self.config = config # Store the config object\n        self.bert = AtomBERT(\n            vocab_size=config.vocab_size,\n            embedding_dim=config.embedding_dim,\n            hidden_size=config.hidden_size,\n            num_layers=config.num_layers,\n            num_attention_heads=config.num_attention_heads,\n            intermediate_size=config.intermediate_size,\n            num_classes=2, # For SOP\n            max_seq_length=config.max_seq_length,\n            dropout_rate=config.dropout_rate,\n            type_vocab_size=config.type_vocab_size if hasattr(config, 'type_vocab_size') else 2\n        )\n        self.mlm_head = nn.Sequential(\n        nn.Linear(config.hidden_size, config.hidden_size),\n        nn.LayerNorm(config.hidden_size),\n        nn.Linear(config.hidden_size, config.vocab_size)\n        )\n        self.sop_head = nn.Linear(config.hidden_size, 2)\n\n\n\n    def forward(self, input_ids, attention_mask, masked_labels=None, sentence_order_labels=None, token_type_ids=None):\n        outputs = self.bert(input_ids, attention_mask, token_type_ids) # Shape: (batch_size, seq_len, hidden_size)\n        encoder_output = outputs[0]\n        pooled_output = outputs[1]\n        # MLM Prediction\n        prediction_logits_mlm = self.mlm_head(encoder_output) # Shape: (batch_size, seq_len, vocab_size)\n\n        # SOP Prediction (using the pooled output - we might need to adjust this)\n        #pooled_output = outputs[:, 0, :] # Taking the [CLS] token representation\n        prediction_logits_sop = self.sop_head(pooled_output) # Shape: (batch_size, 2)\n\n        total_loss = None\n        if masked_labels is not None and sentence_order_labels is not None:\n            loss_fct_mlm = nn.CrossEntropyLoss()\n            masked_loss = loss_fct_mlm(prediction_logits_mlm.view(-1, self.config.vocab_size), masked_labels.view(-1))\n\n            loss_fct_sop = nn.CrossEntropyLoss()\n            sop_loss = loss_fct_sop(prediction_logits_sop.view(-1, 2), sentence_order_labels.view(-1))\n\n            total_loss = masked_loss + sop_loss # You might want to weigh these differently\n\n        elif masked_labels is not None:\n            loss_fct_mlm = nn.CrossEntropyLoss()\n            total_loss = loss_fct_mlm(prediction_logits_mlm.view(-1, self.config.vocab_size), masked_labels.view(-1))\n\n        elif sentence_order_labels is not None:\n            loss_fct_sop = nn.CrossEntropyLoss()\n            total_loss = loss_fct_sop(prediction_logits_sop.view(-1, 2), sentence_order_labels.view(-1))\n\n        return total_loss, prediction_logits_mlm, prediction_logits_sop","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T20:43:22.187415Z","iopub.execute_input":"2025-03-29T20:43:22.187708Z","iopub.status.idle":"2025-03-29T20:43:22.195481Z","shell.execute_reply.started":"2025-03-29T20:43:22.187684Z","shell.execute_reply":"2025-03-29T20:43:22.194428Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"class AtomBERTConfig:\n    def __init__(\n        self,\n        vocab_size,\n        embedding_dim=128,\n        hidden_size=768,\n        num_layers=4,\n        num_attention_heads=4,\n        intermediate_size=1500,\n        num_classes=2, # For SOP\n        max_seq_length=128,\n        dropout_rate=0.1,\n        type_vocab_size = 2\n    ):\n        self.vocab_size = vocab_size\n        self.embedding_dim = embedding_dim\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.num_attention_heads = num_attention_heads\n        self.intermediate_size = intermediate_size\n        self.num_classes = num_classes\n        self.max_seq_length = max_seq_length\n        self.dropout_rate = dropout_rate\n        self.type_vocab_size = type_vocab_size","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T20:43:25.326757Z","iopub.execute_input":"2025-03-29T20:43:25.327054Z","iopub.status.idle":"2025-03-29T20:43:25.331589Z","shell.execute_reply.started":"2025-03-29T20:43:25.327033Z","shell.execute_reply":"2025-03-29T20:43:25.330785Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"wiki_text_dataset = load_dataset(\"wikitext\", \"wikitext-103-raw-v1\")\nprint(wiki_text_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T20:43:27.719123Z","iopub.execute_input":"2025-03-29T20:43:27.719412Z","iopub.status.idle":"2025-03-29T20:43:41.119646Z","shell.execute_reply.started":"2025-03-29T20:43:27.719392Z","shell.execute_reply":"2025-03-29T20:43:41.118824Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09cfd31fb684478c8d305acff72dbdb6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/733k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"276dac3c166b4759b47089f3cbfe54a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00002.parquet:   0%|          | 0.00/157M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d56211b390243249a734822797a7ae3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00001-of-00002.parquet:   0%|          | 0.00/157M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e09f948f5544f78982bc50b96f71704"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation-00000-of-00001.parquet:   0%|          | 0.00/657k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba0ac59806c549e48395fb4219b1c38c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/4358 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9842fb7878f94edc926a40142344b98d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/1801350 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e214baf15a524624b79c62bd2f932a4a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/3760 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e967ee5f2b843ec82b067285909cd53"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    test: Dataset({\n        features: ['text'],\n        num_rows: 4358\n    })\n    train: Dataset({\n        features: ['text'],\n        num_rows: 1801350\n    })\n    validation: Dataset({\n        features: ['text'],\n        num_rows: 3760\n    })\n})\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"vocab_size = tokenizer.vocab_size\nlearning_rate = 5e-5\n\n# Move the model to the device (GPU if available)\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n# Recall or re-initialize your tokenizer if needed\nvocab_size = tokenizer.vocab_size\n\n# Create the configuration\nconfig = AtomBERTConfig(vocab_size=vocab_size) # You can customize other parameters here if needed\n\n# Instantiate the AtomBERTForPretraining model\nmodelpretrain = AtomBERTForPretraining(config)\n\nprint(f\"Model instantiated with {config}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T20:43:44.752407Z","iopub.execute_input":"2025-03-29T20:43:44.752678Z","iopub.status.idle":"2025-03-29T20:43:45.169751Z","shell.execute_reply.started":"2025-03-29T20:43:44.752658Z","shell.execute_reply":"2025-03-29T20:43:45.168816Z"}},"outputs":[{"name":"stdout","text":"Model instantiated with <__main__.AtomBERTConfig object at 0x78c8cef7ada0>\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"def count_parameters(model):\n    total_params = 0\n    trainable_params = 0\n    non_trainable_params = 0\n\n    for name, param in model.named_parameters():\n        num_params = param.numel()\n        # if requires_grad is True, then it is a trainable parameter\n        if param.requires_grad:\n            trainable_params += num_params\n        else:\n            non_trainable_params += num_params\n        total_params += num_params\n\n    print(f\"Total Parameters: {total_params:,}\")\n    print(f\"Trainable Parameters: {trainable_params:,}\")\n    print(f\"Non-trainable Parameters: {non_trainable_params:,}\")\nprint(\"Basic Model: \\n\")\ncount_parameters(modelpretrain.bert)\nprint(\"Total Pretraining Model: \\n\")\ncount_parameters(modelpretrain)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T20:43:47.823498Z","iopub.execute_input":"2025-03-29T20:43:47.823806Z","iopub.status.idle":"2025-03-29T20:43:47.831320Z","shell.execute_reply.started":"2025-03-29T20:43:47.823780Z","shell.execute_reply":"2025-03-29T20:43:47.830485Z"}},"outputs":[{"name":"stdout","text":"Basic Model: \n\nTotal Parameters: 8,682,460\nTrainable Parameters: 8,682,460\nNon-trainable Parameters: 0\nTotal Pretraining Model: \n\nTotal Parameters: 32,747,544\nTrainable Parameters: 32,747,544\nNon-trainable Parameters: 0\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"# Start a new wandb run to track this script.\nimport wandb\nrun = wandb.init(\n    # Set the wandb entity where your project will be logged (generally your team name).\n    entity=\"hexager-manipal\",\n    # Set the wandb project where this run will be logged.\n    project=\"MRM-transform_MOD\",\n    # Track hyperparameters and run metadata.\n    config={\n        \"learning_rate\": 0.02,\n        \"architecture\": \"AlBERT-1M\",\n        \"dataset\": \"WikiText-103\",\n        \"epochs\": 4,\n    },\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T20:43:52.196191Z","iopub.execute_input":"2025-03-29T20:43:52.196502Z","iopub.status.idle":"2025-03-29T20:43:59.074194Z","shell.execute_reply.started":"2025-03-29T20:43:52.196476Z","shell.execute_reply":"2025-03-29T20:43:59.073549Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250329_204352-cgmn32e4</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/hexager-manipal/MRM-transform_MOD/runs/cgmn32e4' target=\"_blank\">mild-night-1</a></strong> to <a href='https://wandb.ai/hexager-manipal/MRM-transform_MOD' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/hexager-manipal/MRM-transform_MOD' target=\"_blank\">https://wandb.ai/hexager-manipal/MRM-transform_MOD</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/hexager-manipal/MRM-transform_MOD/runs/cgmn32e4' target=\"_blank\">https://wandb.ai/hexager-manipal/MRM-transform_MOD/runs/cgmn32e4</a>"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"# Define parameters (ensure max_seq_length and batch_size are defined)\nmax_seq_length = 128  # Example value, adjust as needed\nbatch_size = 64      # Example value, adjust as needed\nnum_epochs = 4\nlearning_rate = 1e-4\nweight_decay = 0.01\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n\n# Load tokenizer\ntokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n\n# Load dataset\nwiki_text_dataset = load_dataset(\"wikitext\", \"wikitext-103-raw-v1\")\n\n# Tokenize dataset\ndef tokenize_function(examples):\n    return tokenizer(examples[\"text\"], truncation=True, padding='max_length', max_length=max_seq_length)\ntokenized_train_dataset = wiki_text_dataset[\"train\"].map(tokenize_function, batched=True)\n\n# Prepare MLM data\ndef prepare_mlm_data(examples):\n    input_ids = torch.tensor(examples[\"input_ids\"])\n    batch_size_local = len(input_ids)\n    sequence_length = len(input_ids[0])\n    mask_prob = 0.15\n    mask_token_id = tokenizer.mask_token_id\n    pad_token_id = tokenizer.pad_token_id\n    cls_token_id = tokenizer.cls_token_id\n    sep_token_id = tokenizer.sep_token_id\n\n    rand = torch.rand(batch_size_local, sequence_length)\n    mask = (rand < mask_prob) & (input_ids != cls_token_id) & (input_ids != sep_token_id) & (input_ids != pad_token_id)\n\n    labels = input_ids.clone()\n    labels[~mask] = -100\n    inputs = input_ids.clone()\n    inputs[mask] = mask_token_id\n\n    return {\"input_ids\": inputs, \"labels\": labels}\nmlm_tokenized_train_dataset = tokenized_train_dataset.map(\n    prepare_mlm_data,\n    batched=True,\n    remove_columns=[\"text\", \"token_type_ids\"]\n)\n\n# Prepare SOP data\nimport re\nfrom datasets import Dataset as HFDataset\n\ndef split_into_sentences_robust(text):\n    sentence_pattern = r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?|!)\\s+'\n    sentences = re.split(sentence_pattern, text)\n    return [s.strip() for s in sentences if s.strip()]\n\nsop_texts_limited = []\nsop_labels_limited = []\ncls_token = tokenizer.cls_token\nsep_token = tokenizer.sep_token\nmax_pairs_per_document = 5\n\nfor example in wiki_text_dataset[\"train\"]:\n    text = example[\"text\"]\n    sentences = split_into_sentences_robust(text)\n    pairs_count = 0\n    for i in range(len(sentences) - 1):\n        if pairs_count >= max_pairs_per_document:\n            break\n        sentence_a = sentences[i]\n        sentence_b = sentences[i + 1]\n        sop_texts_limited.append(cls_token + \" \" + sentence_a + \" \" + sep_token + \" \" + sentence_b)\n        sop_labels_limited.append(0)\n        pairs_count += 1\n        if pairs_count >= max_pairs_per_document:\n            break\n        sop_texts_limited.append(cls_token + \" \" + sentence_b + \" \" + sep_token + \" \" + sentence_a)\n        sop_labels_limited.append(1)\n        pairs_count += 1\n\nsop_dataset = HFDataset.from_dict({\"text\": sop_texts_limited, \"sentence_order_labels\": sop_labels_limited})\n\ndef tokenize_sop_function(examples):\n    return tokenizer(examples[\"text\"], truncation=True, padding='max_length', max_length=max_seq_length)\ntokenized_sop_dataset = sop_dataset.map(tokenize_sop_function, batched=True)\n\n# Set format to PyTorch tensors\nmlm_tokenized_train_dataset.set_format(\"torch\")\ntokenized_sop_dataset.set_format(\"torch\")\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True) # Adjust num_workers\nval_dataloader = DataLoader(val_dataset, batch_size=batch_size, num_workers=4, pin_memory=True) # Adjust num_workers\nmlm_dataloader = DataLoader(\n    mlm_tokenized_train_dataset,\n    batch_size=batch_size,\n    shuffle=True,\n    num_workers=4, # Adjust num_workers\n    pin_memory=True\n)\nsop_dataloader = DataLoader(\n    tokenized_sop_dataset,\n    batch_size=batch_size,\n    shuffle=True,\n    num_workers=4, # Adjust num_workers\n    pin_memory=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T20:44:02.667425Z","iopub.execute_input":"2025-03-29T20:44:02.667756Z","iopub.status.idle":"2025-03-29T21:01:53.603205Z","shell.execute_reply.started":"2025-03-29T20:44:02.667718Z","shell.execute_reply":"2025-03-29T21:01:53.602295Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1801350 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"497b9fe5957b4504944df1ebf55bf9db"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1801350 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"093442f636ea4b759e5465b48d06ab7b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3189245 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"209bc0b38e0c46b6ba5b3b6cbfc78bec"}},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"modelpretrain.to(device)\nfrom torch.optim import AdamW\noptimizer = AdamW(modelpretrain.parameters(), lr=learning_rate, weight_decay=weight_decay)\nwandb.watch(modelpretrain)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T21:01:57.762255Z","iopub.execute_input":"2025-03-29T21:01:57.762568Z","iopub.status.idle":"2025-03-29T21:01:57.988613Z","shell.execute_reply.started":"2025-03-29T21:01:57.762543Z","shell.execute_reply":"2025-03-29T21:01:57.987915Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"counter = 0\nfor epoch in range(num_epochs):\n    modelpretrain.train()\n    total_mlm_loss = 0.0\n    total_sop_loss = 0.0\n\n    # Use zip to iterate concurrently over both dataloaders\n    total_steps = min(len(mlm_dataloader), len(sop_dataloader))\n    progress_bar = tqdm(zip(mlm_dataloader, sop_dataloader), total=total_steps, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n\n    for batch_mlm, batch_sop in progress_bar:\n        counter += 1\n        # Transfer batches to the device\n        mlm_inputs = {k: v.to(device) for k, v in batch_mlm.items()}\n        sop_inputs = {\n                    k: v.to(device) if isinstance(v, torch.Tensor) else v\n                    for k, v in batch_sop.items()\n                    }\n        optimizer.zero_grad()\n\n        # MLM forward pass\n        returned_loss, _, _ = modelpretrain(\n            input_ids=mlm_inputs['input_ids'],\n            attention_mask=mlm_inputs['attention_mask'],\n            masked_labels=mlm_inputs['labels']\n        )\n        mlm_loss = returned_loss\n\n        # SOP forward pass\n        outputs_sop = modelpretrain(\n            input_ids=sop_inputs['input_ids'],\n            attention_mask=sop_inputs['attention_mask'],\n            token_type_ids=sop_inputs.get('token_type_ids', None),\n            sentence_order_labels=sop_inputs['sentence_order_labels']\n        )\n        sop_loss = outputs_sop[0]\n\n        # Combine losses and update\n        total_loss = mlm_loss + sop_loss\n        total_loss.backward()\n        optimizer.step()\n\n        total_mlm_loss += mlm_loss.item()\n        total_sop_loss += sop_loss.item()\n\n        # Log every step (or throttle this if needed)\n        if(counter%15==0):\n            wandb.log({\n                \"mlm_loss\": mlm_loss.item(), \n                \"sop_loss\": sop_loss.item(), \n                \"total_loss\": total_loss.item()\n            })\n        progress_bar.set_postfix({\n            \"mlm_loss\": f\"{mlm_loss.item():.4f}\", \n            \"sop_loss\": f\"{sop_loss.item():.4f}\"\n        })\n\n    avg_mlm_loss = total_mlm_loss / total_steps if total_steps > 0 else 0\n    avg_sop_loss = total_sop_loss / total_steps if total_steps > 0 else 0\n\n    # Logging epoch metrics\n    wandb.log({\n        \"avg_mlm_loss\": avg_mlm_loss, \n        \"avg_sop_loss\": avg_sop_loss, \n        \"epoch\": epoch + 1,\n        \"Total Unsupervised Loss\": total_loss.item()  # Note: last step's loss\n    })\n\n    # Save checkpoint\n    save_path = '/kaggle/working/pretrained_model.pth'\n    torch.save(modelpretrain.state_dict(), save_path)\n    wandb.save(save_path)\n    print(f\"Epoch {epoch+1}/{num_epochs} finished, Average MLM Loss: {avg_mlm_loss:.4f}, Average SOP Loss: {avg_sop_loss:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2025-03-29T21:03:33.263871Z","iopub.execute_input":"2025-03-29T21:03:33.264212Z","iopub.status.idle":"2025-03-29T21:40:17.015276Z","shell.execute_reply.started":"2025-03-29T21:03:33.264182Z","shell.execute_reply":"2025-03-29T21:40:17.006869Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Epoch 1/4:   0%|          | 0/28147 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f311111b3f64e3a9bec0dd5671dbb99"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-d56d0cdbf5ba>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# MLM forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         returned_loss, _, _ = modelpretrain(\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmlm_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmlm_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-23-2c0d470c774e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, masked_labels, sentence_order_labels, token_type_ids)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasked_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence_order_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Shape: (batch_size, seq_len, hidden_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mencoder_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-22-55bf62748a4f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mln\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;31m# Pass through the shared encoder layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0;31m# Residual connection plus per-iteration layer normalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mencoder_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_output\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-19-54e2e818519e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# Self-attention with residual and normalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mnormed_output1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-17-2ec972c69c46>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, mask)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mseq_len_q\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len_q\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":32},{"cell_type":"code","source":"save_path = '/kaggle/working/pretrained_model.pth'  # Replace with your desired path\ntorch.save(modelpretrain.state_dict(), save_path)\nwandb.save(save_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T21:40:23.235220Z","iopub.execute_input":"2025-03-29T21:40:23.235531Z","iopub.status.idle":"2025-03-29T21:40:23.501829Z","shell.execute_reply.started":"2025-03-29T21:40:23.235507Z","shell.execute_reply":"2025-03-29T21:40:23.501173Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve subdirectories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n","output_type":"stream"},{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"['/kaggle/working/wandb/run-20250329_204352-cgmn32e4/files/working/pretrained_model.pth']"},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"class AtomBERTForSequenceClassification(nn.Module):\n    def __init__(self, pretrained_config, num_classes):\n        super().__init__()\n        self.bert = AtomBERT(\n            vocab_size=pretrained_config.vocab_size,\n            embedding_dim=pretrained_config.embedding_dim,\n            hidden_size=pretrained_config.hidden_size,\n            num_layers=pretrained_config.num_layers,\n            num_attention_heads=pretrained_config.num_attention_heads,\n            intermediate_size=pretrained_config.intermediate_size,\n            num_classes=num_classes, # For MNLI this will be 3\n            max_seq_length=pretrained_config.max_seq_length,\n            dropout_rate=pretrained_config.dropout_rate,\n            type_vocab_size=pretrained_config.type_vocab_size if hasattr(pretrained_config, 'type_vocab_size') else 2\n        )\n        self.dropout = nn.Dropout(pretrained_config.dropout_rate)\n        self.classifier = nn.Linear(pretrained_config.hidden_size, num_classes)\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.bert(input_ids, attention_mask)\n        pooled_output = outputs[1] # We typically use the pooled output for classification\n        pooled_output = self.dropout(pooled_output)\n        logits = self.classifier(pooled_output)\n        return logits","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T21:40:27.576479Z","iopub.execute_input":"2025-03-29T21:40:27.576772Z","iopub.status.idle":"2025-03-29T21:40:27.583618Z","shell.execute_reply.started":"2025-03-29T21:40:27.576751Z","shell.execute_reply":"2025-03-29T21:40:27.582796Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"\n\n# Define the path to your saved pretrained weights file\npretrained_weights_path = '/kaggle/working/pretrained_model.pth' # Replace with the actual path to your saved file\n\n# Load the configuration of your pretrained model\n# Make sure these values match what you used for pretraining\npretrained_config = AtomBERTConfig(\n    vocab_size=tokenizer.vocab_size,\n    embedding_dim=128,\n    hidden_size=768,\n    num_layers=4,\n    num_attention_heads=4,\n    intermediate_size=1500,\n    max_seq_length=128,\n    dropout_rate=0.1,\n    type_vocab_size=2\n)\n\n# Instantiate the model for sequence classification (for MNLI with 3 classes)\nnum_classes_mnli = 3\nmodel_for_mnli = AtomBERTForSequenceClassification(pretrained_config, num_classes_mnli)\n\n# Load the state dictionary of the pretrained model\npretrained_state_dict = torch.load(pretrained_weights_path, map_location=torch.device(device)) # Ensure device consistency\n\n# Create a new dictionary to store only the 'bert' weights\npretrained_bert_state_dict = {}\nfor name, param in pretrained_state_dict.items():\n    if name.startswith('bert.'):\n        pretrained_bert_state_dict[name[len('bert.'):]] = param\n\n# Load the pretrained weights into the 'bert' part of the sequence classification model\nmodel_for_mnli.bert.load_state_dict(pretrained_bert_state_dict)\n\nprint(\"Pretrained weights loaded successfully into the sequence classification model.\")\n\n# Move the fine-tuning model to the device\nmodel_for_mnli.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T21:40:31.627272Z","iopub.execute_input":"2025-03-29T21:40:31.627563Z","iopub.status.idle":"2025-03-29T21:40:31.862471Z","shell.execute_reply.started":"2025-03-29T21:40:31.627541Z","shell.execute_reply":"2025-03-29T21:40:31.861787Z"}},"outputs":[{"name":"stdout","text":"Pretrained weights loaded successfully into the sequence classification model.\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-35-6f785b1d3dda>:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  pretrained_state_dict = torch.load(pretrained_weights_path, map_location=torch.device(device)) # Ensure device consistency\n","output_type":"stream"},{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"AtomBERTForSequenceClassification(\n  (bert): AtomBERT(\n    (embedding): FactorizedEmbedding(\n      (word_embeddings): Embedding(30522, 128)\n      (token_type_embeddings): Embedding(2, 128)\n      (projection): Linear(in_features=128, out_features=768, bias=True)\n    )\n    (positional_encoding): PositionalEncoding(\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder_layer): TransformerEncoderLayer(\n      (self_attention): MultiHeadSelfAttention(\n        (query): Linear(in_features=768, out_features=768, bias=True)\n        (key): Linear(in_features=768, out_features=768, bias=True)\n        (value): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n        (output): Linear(in_features=768, out_features=768, bias=True)\n      )\n      (feed_forward): FeedForwardNetwork(\n        (dense1): Linear(in_features=768, out_features=1500, bias=True)\n        (relu): ReLU()\n        (dense2): Linear(in_features=1500, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (layer_norms): ModuleList(\n      (0-3): 4 x LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    )\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=3, bias=True)\n)"},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"model_finetune = AtomBERTForSequenceClassification(pretrained_config, 3)\nmodel_finetune.to(device)\n# 5. Load the pretrained weights into the new model\n# Load the state dictionary of the pretrained model\npretrained_state_dict = torch.load(pretrained_weights_path, map_location=torch.device(device)) # Ensure device consistency\n\n# Create a new dictionary to store only the 'bert' weights\npretrained_bert_state_dict = {}\nfor name, param in pretrained_state_dict.items():\n    if name.startswith('bert.'):\n        pretrained_bert_state_dict[name[len('bert.'):]] = param\n\n# Load the pretrained weights into the 'bert' part of the sequence classification model\nmodel_finetune.bert.load_state_dict(pretrained_bert_state_dict)\nlearning_rate_finetune = 2e-5\noptimizer = AdamW(model_finetune.parameters(), lr=learning_rate_finetune)\nmodel_finetune.to(device)\n# 9. Define the loss function separately\ncriterion = nn.CrossEntropyLoss()\n# 10. Define your training loop (modified for custom model)\nnum_epochs_finetune = 3\nfor epoch in range(num_epochs_finetune):\n    model_finetune.train()\n    total_loss = 0\n    for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs_finetune}\"):\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n        optimizer.zero_grad()\n        outputs = model_finetune(input_ids, attention_mask=attention_mask) # Forward pass without labels\n        logits = outputs # Assuming your model's forward returns the logits directly\n        loss = criterion(logits, labels) # Calculate the loss\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n    print(f\"Epoch {epoch+1} Training Loss: {total_loss/len(train_dataloader)}\")\n\n    # Evaluation loop (modified for custom model)\n    model_finetune.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for batch in tqdm(val_dataloader, desc=\"Evaluating\"):\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n            outputs = model_finetune(input_ids, attention_mask=attention_mask) # Forward pass without labels\n            logits = outputs\n            _, predicted = torch.max(logits, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    accuracy = 100 * correct / total\n    print(f\"Epoch {epoch+1} Validation Accuracy: {accuracy:.2f}%\")\n\nprint(\"Fine-tuning finished!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T21:40:40.598749Z","iopub.execute_input":"2025-03-29T21:40:40.599095Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-36-deff463ce58f>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  pretrained_state_dict = torch.load(pretrained_weights_path, map_location=torch.device(device)) # Ensure device consistency\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 1/3:   0%|          | 0/6136 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"edf70329df46445191aa8a62fc82d40b"}},"metadata":{}}],"execution_count":null}]}